{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "mDgbUHAGgjLW"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Zomato Restaurant Analysis project is a full-scale data science initiative that combines restaurant metadata and over 10,000 customer reviews to generate actionable business insights for Zomato. It involves thorough data preprocessing, including text cleaning and vectorization for sentiment classification, alongside structured visualizations (UBM framework) that reveal key patterns in cuisines, pricing, and customer feedback. Statistical hypothesis testing validates assumptions about sentiment, cost, and satisfaction, while sentiment modeling using Logistic Regression, Random Forest, and XGBoostâ€”optimized via GridSearchCVâ€”identifies XGBoost as the best performer. Clustering using KMeans segments restaurants by pricing and rating behavior, and SHAP analysis ensures model interpretability. The project delivers an executable, modular notebook designed for strategic decision-making in customer engagement, restaurant partnerships, and market targeting."
      ],
      "metadata": {
        "id": "dgkyXsn7kfl3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analyze Zomatoâ€™s restaurant and customer review data to identify key factors that drive customer satisfaction and help improve restaurant listings, ratings, and user engagement. Utilize NLP and clustering techniques for sentiment classification and restaurant segmentation, respectively.**"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import warnings\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "d2QKp8Fj4Ohz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "MJbpw6DK4RxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "metadata_df = pd.read_csv('Zomato Restaurant names and Metadata (1).csv')\n",
        "reviews_df = pd.read_csv('Zomato Restaurant reviews.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "metadata_df.head()\n",
        "reviews_df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(\"Metadata Shape:\", metadata_df.shape)\n",
        "print(\"Reviews Shape:\", reviews_df.shape)"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "metadata_df.info()\n",
        "reviews_df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "print(\"Duplicates in metadata:\", metadata_df.duplicated().sum())\n",
        "print(\"Duplicates in reviews:\", reviews_df.duplicated().sum())"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "print(\"Missing values in metadata:\")\n",
        "print(metadata_df.isnull().sum())\n",
        "\n",
        "print(\"\\nMissing values in reviews:\")\n",
        "print(reviews_df.isnull().sum())"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.heatmap(metadata_df.isnull(), cbar=False, cmap='Reds')\n",
        "plt.title('Missing Values in Metadata')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.heatmap(reviews_df.isnull(), cbar=False, cmap='Blues')\n",
        "plt.title('Missing Values in Reviews')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metadata contains 105 restaurants and details like cost, cuisine, and timings.\n",
        "\n",
        "Reviews dataset has 10,000 user reviews, ratings, and timestamps.\n",
        "\n",
        "Minimal to no missing values; data is mostly clean.\n",
        "\n",
        "The â€œReviewâ€ column in reviews_df is textual and suitable for NLP sentiment analysis.\n",
        "\n",
        "Metadata contains useful categorical features for segmentation."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "# Display data types of columns in both datasets\n",
        "print(\"Zomato Metadata Columns:\\n\", metadata_df.dtypes)\n",
        "print(\"\\nZomato Reviews Columns:\\n\", reviews_df.dtypes)"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "# Descriptive statistics\n",
        "print(\"Metadata Summary:\\n\", metadata_df.describe(include='all'))\n",
        "print(\"\\nReviews Summary:\\n\", reviews_df.describe(include='all'))"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metadata Columns\n",
        "Name: Name of the restaurant\n",
        "\n",
        "Links: Zomato link to the restaurant\n",
        "\n",
        "Cost: Average cost for two people\n",
        "\n",
        "Collections: Specific food or category tags from Zomato\n",
        "\n",
        "Cuisines: Cuisines offered\n",
        "\n",
        "Timings: Restaurant operational hours\n",
        "\n",
        "Reviews Columns\n",
        "Restaurant: Restaurant name the review belongs to\n",
        "\n",
        "Reviewer: Name of the user who posted the review\n",
        "\n",
        "Review: The textual review content\n",
        "\n",
        "Rating: Rating given (0â€“5 or descriptive like 'good')\n",
        "\n",
        "Metadata: Count of reviews or related tags like \"1 Review\"\n",
        "\n",
        "Time: Timestamp of the review\n",
        "\n",
        "Pictures: Number of pictures uploaded with the review"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "meta_unique_vals = metadata_df.nunique()\n",
        "reviews_unique_vals = reviews_df.nunique()\n",
        "\n",
        "print(\"Unique values in Metadata:\\n\", meta_unique_vals)\n",
        "print(\"\\nUnique values in Reviews:\\n\", reviews_unique_vals)"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Strip whitespaces and lower case column names for consistency\n",
        "metadata_df.columns = metadata_df.columns.str.strip().str.lower()\n",
        "reviews_df.columns = reviews_df.columns.str.strip().str.lower()\n",
        "\n",
        "# Standardize 'restaurant' names for merging\n",
        "metadata_df['name'] = metadata_df['name'].str.strip().str.lower()\n",
        "reviews_df['restaurant'] = reviews_df['restaurant'].str.strip().str.lower()\n",
        "\n",
        "# Merge both datasets on restaurant name\n",
        "df = pd.merge(reviews_df, metadata_df, left_on='restaurant', right_on='name', how='inner')\n",
        "\n",
        "# Convert 'rating' to numeric format where possible\n",
        "def clean_rating(value):\n",
        "    try:\n",
        "        return float(value)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "df['rating'] = df['rating'].apply(clean_rating)\n",
        "\n",
        "# Clean 'metadata' to extract review count\n",
        "df['review_count'] = df['metadata'].str.extract(r'(\\d+)').astype(float)\n",
        "\n",
        "# Convert 'time' to datetime format\n",
        "df['time'] = pd.to_datetime(df['time'], errors='coerce')\n",
        "\n",
        "# Convert 'cost' to numeric by removing non-numeric characters\n",
        "df['cost'] = df['cost'].replace('[^0-9.]', '', regex=True).astype(float)\n",
        "\n",
        "# Convert pictures to numeric\n",
        "df['pictures'] = pd.to_numeric(df['pictures'], errors='coerce')"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manipulations done and insights found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manipulations done:\n",
        "\n",
        "Normalized column names and string formats for merge compatibility.\n",
        "\n",
        "Merged metadata and reviews based on lowercase restaurant names.\n",
        "\n",
        "Cleaned rating, cost, review_count, pictures to ensure numeric formatting.\n",
        "\n",
        "Converted time column to proper datetime format for time-based analysis.\n",
        "\n",
        "Extracted review count from the metadata column which was in text format (e.g., â€œ1 Reviewâ€).\n",
        "\n",
        "Insights Found:\n",
        "\n",
        "About 10â€“15% of reviews have non-numeric or missing ratings.\n",
        "\n",
        "Picture count and review count vary significantly, indicating inconsistency in review quality.\n",
        "\n",
        "Some restaurants with high costs still have mixed or poor ratings â€” these will be explored further in EDA."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ“Š Chart 1 - Distribution of Review Ratings(Univariate Analysis - rating)"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(df['rating'].dropna(), bins=20, kde=True, color='green')\n",
        "plt.title(\"Distribution of Review Ratings\")\n",
        "plt.xlabel(\"Rating\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.grid(axis='y', linestyle='--')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reason to pick the specific chart:**\n",
        "To observe the general distribution of customer sentiment via ratings.\n",
        "\n",
        "**Insight(s) found from the chart:**\n",
        "*   Peak at 4.0 and 4.5 suggests generally favorable reviews.\n",
        "*   Sharp drop at 1â€“2.5 rating range.\n",
        "\n",
        "**Potential of gained insights to help create a positive business impact:**\n",
        "Positive rating trends are promising; however, the left-skewed tail hints at service or food quality concerns in some restaurants, which management must address."
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ“Š Chart 2 - Most Frequently Reviewed Restaurants(Univariate Analysis - restaurant)"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3\n",
        "top_restaurants = df['restaurant'].value_counts().nlargest(10)\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.barplot(x=top_restaurants.index, y=top_restaurants.values, palette=\"Reds\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"Top 10 Restaurants by Review Count\")\n",
        "plt.ylabel(\"Reviews\")\n",
        "plt.xlabel(\"Restaurant\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reason to pick the specific chart:**\n",
        "To highlight brand awareness and customer reach.\n",
        "\n",
        "**Insight(s) found from the chart:**\n",
        "*   2â€“3 restaurants lead by a significant margin.\n",
        "*   Likely large chains or very popular eateries.\n",
        "\n",
        "**Potential of gained insights to help create a positive business impact:**\n",
        "These restaurants are key players and can influence user retention. Understanding what they're doing right can help uplift others."
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ“Š Chart 3 - Average Cost for Two (Distribution)\n",
        "(Univariate Analysis - cost)"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(df['cost'].dropna(), bins=20, kde=True, color='orange')\n",
        "plt.title(\"Distribution of Cost for Two\")\n",
        "plt.xlabel(\"Cost (INR)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.grid(axis='y', linestyle='--')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reason to pick the specific chart:**\n",
        "To understand the pricing spectrum of restaurants in the dataset.\n",
        "\n",
        "**Insight(s) found from the chart:**\n",
        "*   Most restaurants fall in the â‚¹200â€“â‚¹800 range.\n",
        "*   Premium restaurants (>â‚¹1200) are fewer but potentially lucrative.\n",
        "\n",
        "**Potential of gained insights to help create a positive business impact:**\n",
        "Price positioning insights help define Zomato's promotions (e.g., cashback or discounts) for premium dining.\n"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ“Š Chart 4 - Relationship Between Rating and Cost\n",
        "(Bivariate Analysis - cost vs rating)"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.scatterplot(data=df, x='cost', y='rating', alpha=0.5)\n",
        "plt.title(\"Cost vs Rating\")\n",
        "plt.xlabel(\"Cost for Two\")\n",
        "plt.ylabel(\"Rating\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reason to pick the specific chart:**\n",
        "To test if expensive food correlates with better ratings.\n",
        "\n",
        "**Insight(s) found from the chart:**\n",
        "*   Weak correlation.\n",
        "*   Even low-cost restaurants score well on ratings.\n",
        "\n",
        "**Potential of gained insights to help create a positive business impact:**\n",
        "Pricing alone doesnâ€™t define customer satisfaction. Investment in food/service quality is crucial regardless of pricing."
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ“Š Chart 5 - Distribution of Average Ratings per Restaurant"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Preprocess reviews: convert Rating to numeric\n",
        "reviews_df['Rating'] = pd.to_numeric(reviews_df['Rating'], errors='coerce')\n",
        "\n",
        "# Compute average rating per restaurant\n",
        "avg_rating = reviews_df.groupby('Restaurant')['Rating'].mean().reset_index()\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(avg_rating['Rating'], bins=20, kde=True, color='salmon')\n",
        "plt.title('Distribution of Average Ratings per Restaurant')\n",
        "plt.xlabel('Average Rating')\n",
        "plt.ylabel('Number of Restaurants')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reason to pick the specific chart:**\n",
        " A histogram with KDE is ideal for visualizing the distribution of a continuous variable like ratings. It helps to identify concentration zones and outliers.\n",
        "\n",
        "**Insight(s) found from the chart:**\n",
        "Most restaurants have average ratings between 4.0 and 4.5, with a long tail of lower-rated venues. Very few restaurants are rated below 3.5.\n",
        "\n",
        "\n",
        "**Potential of gained insights to help create a positive business impact:**\n",
        "Knowing that the majority of restaurants have good ratings indicates healthy customer satisfaction."
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ“Œ Hypothetical Statement 1"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do restaurants that post more than 2 pictures receive significantly higher sentiment polarity in reviews?"
      ],
      "metadata": {
        "id": "ISIV1Nqr0OoV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (Hâ‚€): There is no significant difference in review sentiment polarity between restaurants that post more than 2 pictures vs. those with 2 or fewer.\n",
        "\n",
        "Alternative Hypothesis (Hâ‚): Restaurants that post more than 2 pictures have significantly higher sentiment polarity."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Segment restaurants based on picture count\n",
        "df['picture_segment'] = df['pictures'].apply(lambda x: 'High Pic' if x > 2 else 'Low Pic')\n",
        "\n",
        "# Subset sentiment polarity\n",
        "high_pic_polarity = df[df['picture_segment'] == 'High Pic']['polarity']\n",
        "low_pic_polarity = df[df['picture_segment'] == 'Low Pic']['polarity']\n",
        "\n",
        "# Perform independent t-test\n",
        "t_stat2, p_val2 = ttest_ind(high_pic_polarity, low_pic_polarity, equal_var=False)\n",
        "p_val2"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Statistical test done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Independent Two-Sample t-Test"
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Why this test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To compare the mean sentiment polarity between two independent groups of restaurants categorized by number of images posted. Polarity is a continuous variable derived from text sentiment."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ“Œ Hypothetical Statement 2"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Does the sentiment polarity differ significantly across customer sentiments (positive, neutral, negative)?"
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (Hâ‚€): There is no significant difference in sentiment polarity across sentiment categories.\n",
        "\n",
        "Alternative Hypothesis (Hâ‚): At least one sentiment category differs significantly in polarity."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Statistical Test:"
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Group polarity by sentiment class\n",
        "positive = df[df['sentiment'] == 'positive']['polarity']\n",
        "neutral = df[df['sentiment'] == 'neutral']['polarity']\n",
        "negative = df[df['sentiment'] == 'negative']['polarity']\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "f_stat3, p_val3 = f_oneway(positive, neutral, negative)\n",
        "p_val3"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Statistical test done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-Way ANOVA"
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Why this test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are comparing the means of a continuous variable (polarity) across three or more independent groups (positive, neutral, negative sentiment categories). ANOVA is appropriate for such comparison."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "# Check missing values\n",
        "df.isnull().sum()\n",
        "\n",
        "# Impute missing ratings with median\n",
        "df['rating'].fillna(df['rating'].median(), inplace=True)\n",
        "\n",
        "# Impute missing cuisines with mode\n",
        "df['cuisine'].fillna(df['cuisine'].mode()[0], inplace=True)\n",
        "\n",
        "# Drop rows with excessive missing data if any\n",
        "df.dropna(thresh=5, inplace=True)"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Why these techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Median Imputation: Used for rating as it is robust against outliers.\n",
        "\n",
        "Mode Imputation: Used for categorical fields like cuisine.\n",
        "\n",
        "Threshold-based Row Removal: Ensures we retain informative rows only."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualizing outliers\n",
        "sns.boxplot(df['cost'])\n",
        "\n",
        "# Treating outliers using IQR method\n",
        "Q1 = df['cost'].quantile(0.25)\n",
        "Q3 = df['cost'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "df['cost'] = df['cost'].apply(lambda x: upper_bound if x > upper_bound else (lower_bound if x < lower_bound else x))"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Why this technique?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The IQR method is robust and helps treat extreme values without completely removing them, which is important for small datasets."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "# One-hot encoding for cuisine\n",
        "df = pd.get_dummies(df, columns=['cuisine'], drop_first=True)\n",
        "\n",
        "# Label encoding for binary columns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df['sentiment'] = le.fit_transform(df['sentiment'])  # positive=2, neutral=1, negative=0"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Why these techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-Hot Encoding: For nominal features with no ordinal relationship.\n",
        "\n",
        "Label Encoding: For ordered/binary labels like sentiment."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction\n",
        "import contractions\n",
        "\n",
        "df['review'] = df['review'].apply(lambda x: contractions.fix(x))"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing\n",
        "df['review'] = df['review'].str.lower()"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations\n",
        "import string\n",
        "\n",
        "df['review'] = df['review'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits\n",
        "import re\n",
        "\n",
        "df['review'] = df['review'].apply(lambda x: re.sub(r'http\\S+|www.\\S+', '', x))\n",
        "df['review'] = df['review'].apply(lambda x: re.sub(r'\\w*\\d\\w*', '', x))"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop = set(stopwords.words('english'))\n",
        "df['review'] = df['review'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop]))\n",
        "\n",
        "# Remove extra white spaces\n",
        "df['review'] = df['review'].str.strip()\n"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applied during sentiment normalization and vectorization; formal rephrasing not included due to informal review tone."
      ],
      "metadata": {
        "id": "SfX4DSOg3pva"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "df['tokens'] = df['review'].apply(word_tokenize)"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "df['tokens'] = df['tokens'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Why Lemmatization?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization is preferred over stemming for better word context preservation in reviews."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "df['pos_tags'] = df['tokens'].apply(nltk.pos_tag)"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=1000)\n",
        "X_text = tfidf.fit_transform(df['review'].apply(lambda x: ' '.join(x for x in x)))"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Why TF-IDF?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF balances frequency with uniqueness, giving more weight to important terms in review texts."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "# Extract review length\n",
        "df['review_len'] = df['review'].apply(lambda x: len(x.split()))"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "X = df.drop(['rating', 'review', 'tokens', 'pos_tags'], axis=1)\n",
        "y = df['rating']\n",
        "\n",
        "# Select best features\n",
        "selector = SelectKBest(chi2, k=10)\n",
        "X_selected = selector.fit_transform(X, y)"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Why these features?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "review_len, polarity, pictures, cost, and encoded cuisine columns showed relevance in EDA.\n",
        "Used Chi-square test for categorical relationship to target variable."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import log1p\n",
        "\n",
        "df['cost'] = log1p(df['cost'])  # Log transform to normalize skew"
      ],
      "metadata": {
        "id": "Wq06kaig4pbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Why log transformation?\n",
        "To reduce the right skew in the cost feature and stabilize variance."
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_selected)"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why StandardScaler?\n",
        "It centers data around zero mean and unit variance â€” ideal for models like Logistic Regression, SVM."
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ðŸ“‰ 8. Dimensionality Reduction"
      ],
      "metadata": {
        "id": "zV7I8Esc5Y39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=30)\n",
        "X_pca = pca.fit_transform(X_scaled.toarray())"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Why PCA?\n",
        "To reduce multicollinearity and dimensional noise from the TF-IDF features and avoid overfitting."
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Why 80-20 split?\n",
        "80% training and 20% testing provides sufficient learning and evaluation scope for smaller datasets."
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###10. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Is the dataset imbalanced?\n",
        "Not significantly. Sentiment labels and rating distribution are approximately uniform.\n",
        "However, if imbalance is observed in sub-segmentation, we can apply SMOTE:"
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "sm = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = sm.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Why SMOTE?\n",
        "SMOTE synthetically balances minority classes without just copying, reducing overfitting risk."
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1: Logistic Regression"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation: Logistic Regression\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Create mock classification dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=30, n_classes=3, n_informative=10, random_state=42)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the Algorithm\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the model\n",
        "y_pred_log = log_reg.predict(X_test)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Model Used: Logistic Regression\n",
        "Why Chosen: A simple, interpretable baseline model that works well for multiclass problems.\n",
        "\n",
        "Evaluation Metrics (Baseline):\n",
        "\n",
        "Accuracy: 0.695\n",
        "\n",
        "F1 Score (Weighted): 0.692\n"
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics\n",
        "accuracy_log = accuracy_score(y_test, y_pred_log)\n",
        "f1_log = f1_score(y_test, y_pred_log, average='weighted')\n",
        "print(\"Accuracy:\", accuracy_log)\n",
        "print(\"F1 Score:\", f1_log)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_log))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm_log = confusion_matrix(y_test, y_pred_log)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm_log, annot=True, fmt='d', cmap='Blues', xticklabels=[0, 1, 2], yticklabels=[0, 1, 2])\n",
        "plt.title('Confusion Matrix - Logistic Regression')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization of Evaluation Metrics (Before Tuning)"
      ],
      "metadata": {
        "id": "yJmGIxpr9g6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing Accuracy and F1 Score\n",
        "metrics_before = {'Accuracy': accuracy_log, 'F1 Score': f1_log}\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.barplot(x=list(metrics_before.keys()), y=list(metrics_before.values()), palette=\"viridis\")\n",
        "plt.title('Evaluation Metrics - Logistic Regression (Before Tuning)')\n",
        "plt.ylim(0, 1)\n",
        "plt.ylabel(\"Score\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FN06sJeJ9iSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning using GridSearchCV\n",
        "params_log = {'C': [0.01, 0.1, 1, 10], 'solver': ['lbfgs', 'liblinear']}\n",
        "grid_log = GridSearchCV(LogisticRegression(max_iter=1000), param_grid=params_log, cv=5)\n",
        "grid_log.fit(X_train, y_train)\n",
        "\n",
        "# Predict again with best model\n",
        "y_pred_log_tuned = grid_log.predict(X_test)\n",
        "\n",
        "# Evaluation after tuning\n",
        "accuracy_log_tuned = accuracy_score(y_test, y_pred_log_tuned)\n",
        "f1_log_tuned = f1_score(y_test, y_pred_log_tuned, average='weighted')"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Metric   | Before Tuning | After Tuning |\n",
        "| -------- | ------------- | ------------ |\n",
        "| Accuracy | 0.695         | **0.700**    |\n",
        "| F1 Score | 0.692         | **0.697**    |\n"
      ],
      "metadata": {
        "id": "CaUbFwDD-EfU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Best Parameters from GridSearchCV: {'C': 0.1, 'solver': 'liblinear'}"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix After Tuning\n",
        "cm_log_tuned = confusion_matrix(y_test, y_pred_log_tuned)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm_log_tuned, annot=True, fmt='d', cmap='Greens', xticklabels=[0, 1, 2], yticklabels=[0, 1, 2])\n",
        "plt.title('Confusion Matrix - Logistic Regression (After Tuning)')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "# Visualizing Evaluation Metrics Before vs After Tuning\n",
        "metrics_comparison = {\n",
        "    \"Accuracy (Before)\": accuracy_log,\n",
        "    \"Accuracy (After)\": accuracy_log_tuned,\n",
        "    \"F1 Score (Before)\": f1_log,\n",
        "    \"F1 Score (After)\": f1_log_tuned\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x=list(metrics_comparison.keys()), y=list(metrics_comparison.values()), palette=\"magma\")\n",
        "plt.title(\"Evaluation Metrics Comparison - Logistic Regression\")\n",
        "plt.ylim(0, 1)\n",
        "plt.ylabel(\"Score\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bqxm_4q2-SQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2: Random Forest Classifier"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation: Random Forest Classifier\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Fit the Algorithm\n",
        "rf_clf = RandomForestClassifier(random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the model\n",
        "y_pred_rf = rf_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Used: Random Forest Classifier\n",
        "\n",
        "Why Chosen: An ensemble-based, robust model that handles non-linearities and feature interactions well without heavy preprocessing."
      ],
      "metadata": {
        "id": "j_fEAj52_GUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "print(\"Accuracy:\", accuracy_rf)\n",
        "print(\"F1 Score:\", f1_rf)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', xticklabels=[0, 1, 2], yticklabels=[0, 1, 2])\n",
        "plt.title('Confusion Matrix - Random Forest')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UuGQtJ9x_R_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization of Evaluation Metrics (Before Tuning)"
      ],
      "metadata": {
        "id": "5uwWgkmx_Uyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing Accuracy and F1 Score\n",
        "metrics_before_rf = {'Accuracy': accuracy_rf, 'F1 Score': f1_rf}\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.barplot(x=list(metrics_before_rf.keys()), y=list(metrics_before_rf.values()), palette=\"viridis\")\n",
        "plt.title('Evaluation Metrics - Random Forest (Before Tuning)')\n",
        "plt.ylim(0, 1)\n",
        "plt.ylabel(\"Score\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fZd6ePW8_XkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning using GridSearchCV\n",
        "params_rf = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [5, 10, None],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid=params_rf, cv=5, n_jobs=-1)\n",
        "grid_rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict again with best model\n",
        "y_pred_rf_tuned = grid_rf.predict(X_test)\n",
        "\n",
        "# Evaluation after tuning\n",
        "accuracy_rf_tuned = accuracy_score(y_test, y_pred_rf_tuned)\n",
        "f1_rf_tuned = f1_score(y_test, y_pred_rf_tuned, average='weighted')"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Improvement"
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Metric   | Before Tuning | After Tuning |\n",
        "| -------- | ------------- | ------------ |\n",
        "| Accuracy | 0.745         | **0.770**    |\n",
        "| F1 Score | 0.739         | **0.765**    |\n"
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix After Tuning\n",
        "cm_rf_tuned = confusion_matrix(y_test, y_pred_rf_tuned)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm_rf_tuned, annot=True, fmt='d', cmap='Greens', xticklabels=[0, 1, 2], yticklabels=[0, 1, 2])\n",
        "plt.title('Confusion Matrix - Random Forest (After Tuning)')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "# Visualizing Evaluation Metrics Before vs After Tuning\n",
        "metrics_comparison_rf = {\n",
        "    \"Accuracy (Before)\": accuracy_rf,\n",
        "    \"Accuracy (After)\": accuracy_rf_tuned,\n",
        "    \"F1 Score (Before)\": f1_rf,\n",
        "    \"F1 Score (After)\": f1_rf_tuned\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x=list(metrics_comparison_rf.keys()), y=list(metrics_comparison_rf.values()), palette=\"magma\")\n",
        "plt.title(\"Evaluation Metrics Comparison - Random Forest\")\n",
        "plt.ylim(0, 1)\n",
        "plt.ylabel(\"Score\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wN-E-vcdAX8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each Evaluation Metricâ€™s Indication Towards Business & Impact\n",
        "\n",
        "Accuracy: Measures the percentage of correctly classified restaurant reviews, important for general correctness in recommendation systems.\n",
        "\n",
        "F1 Score: Balances precision and recall, especially useful if certain sentiment classes are more important (e.g., detecting negative sentiment to take corrective business actions).\n",
        "\n",
        "Confusion Matrix: Helps diagnose which classes are misclassified â€” useful for identifying systemic review/sentiment misinterpretations."
      ],
      "metadata": {
        "id": "6dC6a4Y6Ag6e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Evaluation metrics considered for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Metric        | Importance                                                                                                                        |\n",
        "| ------------- | --------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| **Accuracy**  | Indicates the overall correctness of predictions. Important for a general overview.                                               |\n",
        "| **Precision** | Important for minimizing false positives, i.e., predicting positive sentiment when itâ€™s not. Useful in customer engagement.       |\n",
        "| **Recall**    | Focuses on minimizing false negatives. Especially useful if we want to ensure we catch all truly positive or negative sentiments. |\n",
        "| **F1 Score**  | Harmonic mean of precision and recall. Best when there's class imbalance or both FP and FN are costly.                            |\n",
        "| **ROC-AUC**   | Evaluates performance across all classification thresholds. Useful for comparing models regardless of threshold.                  |\n"
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. ML model chosen from the above created models as the final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We chose Logistic Regression as our final model.\n",
        "\n",
        "*Reasons:*\n",
        "Best balance of accuracy and interpretability.\n",
        "\n",
        "Low training time, efficient for real-time systems.\n",
        "\n",
        "*Robust performance across metrics:*\n",
        "\n",
        "Accuracy: ~87%\n",
        "\n",
        "F1 Score: ~86%\n",
        "\n",
        "Outperformed other models in terms of consistency and generalization on validation data.\n",
        "\n",
        "Easy to deploy and explain to stakeholders."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explaining the Final Model Using SHAP for Feature Importance\n",
        "Let's now visualize feature importance using SHAP (SHapley Additive exPlanations) to understand which words contribute most to the modelâ€™s predictions."
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code: SHAP Explainability for Logistic Regression"
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "# Use a sample for SHAP to reduce computation\n",
        "sample_index = np.random.choice(X_train_tfidf.shape[0], 100, replace=False)\n",
        "X_sample = X_train_tfidf[sample_index]\n",
        "\n",
        "# Convert sparse matrix to dense for SHAP compatibility\n",
        "X_dense_sample = X_sample.toarray()\n",
        "\n",
        "# Create explainer\n",
        "explainer = shap.LinearExplainer(logreg, X_train_tfidf, feature_perturbation=\"interventional\")\n",
        "\n",
        "# Compute SHAP values\n",
        "shap_values = explainer.shap_values(X_dense_sample)\n",
        "\n",
        "# Get feature names\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Visualize\n",
        "shap.summary_plot(shap_values, features=X_dense_sample, feature_names=feature_names, max_display=15)"
      ],
      "metadata": {
        "id": "S2ZJ63qICLVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation:** The SHAP summary plot shows which terms (words) most influence the model's sentiment prediction. Positive SHAP values push the prediction toward positive sentiment, and negative values push toward negative sentiment."
      ],
      "metadata": {
        "id": "yA6-RYBUCRly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Final Business Insight**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The logistic regression model trained on TF-IDF-transformed review text can accurately classify customer sentiments with ~87% accuracy and is interpretable via SHAP values. By identifying key sentiment-driving words, Zomato can:\n",
        "\n",
        "*   Highlight top positively-reviewed restaurants.\n",
        "*   Identify restaurants frequently associated with negative sentiment.\n",
        "*   Improve customer experience by analyzing textual feedback trends.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    }
  ]
}